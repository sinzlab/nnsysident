{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datajoint as dj\n",
    "dj.config['database.host'] = os.environ['DJ_HOST']\n",
    "dj.config['database.user'] = os.environ['DJ_USER']\n",
    "dj.config['database.password'] = os.environ['DJ_PASS']\n",
    "dj.config['enable_python_native_blobs'] = True\n",
    "\n",
    "name = \"simdata\"\n",
    "dj.config['schema_name'] = f\"konstantin_nnsysident_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import string\n",
    "import numpy as np\n",
    "import pickle \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "import nnfabrik\n",
    "from nnfabrik.main import *\n",
    "from nnfabrik import builder\n",
    "from nnfabrik.utility.hypersearch import Bayesian\n",
    "\n",
    "from neuralpredictors.measures import corr\n",
    "\n",
    "from nnsysident.tables.scoring import OracleScore, OracleScoreTransfer\n",
    "from nnsysident.tables.experiments import *\n",
    "from nnsysident.tables.bayesian import *\n",
    "from nnsysident.datasets.mouse_loaders import static_shared_loaders\n",
    "from nnsysident.datasets.mouse_loaders import static_loaders\n",
    "from nnsysident.datasets.mouse_loaders import static_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer(old_experiment_name):\n",
    "    # prepare the Transfer table in a way that all the info about the transferred model is in the DataFrame. Just pd.merge (on transfer_fn and transfer_hash)\n",
    "    # it then with the model that the transferred model was used for. \n",
    "    transfer = pd.DataFrame(Transfer.fetch())\n",
    "    transfer = pd.concat([transfer, transfer['transfer_config'].apply(pd.Series)], axis = 1).drop('transfer_config', axis = 1)\n",
    "\n",
    "    tm = pd.DataFrame((TrainedModel * Dataset * Seed * Experiments.Restrictions & 'experiment_name = \"{}\"'.format(old_experiment_name)).fetch()).rename(\n",
    "        columns = {'model_hash': 't_model_hash', 'trainer_hash': 't_trainer_hash', 'dataset_hash': 't_dataset_hash'})\n",
    "    tm = tm.sort_values('score', ascending=False).drop_duplicates(['t_model_hash', 't_trainer_hash', 't_dataset_hash'])\n",
    "\n",
    "    transfer = pd.merge(transfer, tm, how='inner', on=['t_model_hash', 't_trainer_hash', 't_dataset_hash'])\n",
    "    transfer = pd.concat([transfer, transfer['dataset_config'].apply(pd.Series)], axis = 1).drop('dataset_config', axis = 1)\n",
    "    transfer.columns = ['t_' + col if col[:2] != 't_' and col[:8] != 'transfer'  else col for col in transfer.columns]\n",
    "    transfer = transfer.sort_values(['t_neuron_n', 't_image_n', 't_neuron_base_seed', 't_image_base_seed'])\n",
    "    return transfer\n",
    "\n",
    "def baseline(data, tier):\n",
    "    \"\"\" Function to estimate the highest possible correlation based on the ground truth\"\"\"\n",
    "    # get dataset\n",
    "    for loc, row in data_.iterrows():\n",
    "        dataset_config = row['dataset_config']\n",
    "        dataset_config.update(seed=1)\n",
    "        dataloaders = builder.get_data(row['dataset_fn'], dataset_config)\n",
    "        dataset = dataloaders['train']['0-0-3-0'].dataset\n",
    "        dataset.transforms = []\n",
    "        break\n",
    "    # Extract data\n",
    "    idx = dataset.trial_info.tiers == tier\n",
    "    gts = np.array([gt for gt in dataset.neurons.ground_truths]).T[idx]\n",
    "    resps = np.array([datapoint.responses for datapoint in dataset])[idx]\n",
    "    # Compute correlation and return\n",
    "    return np.mean(corr(resps, gts, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triple plot for sim data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct\n",
    "data = pd.DataFrame()\n",
    "for experiment_name in ['SIM, Direct, se2d_spatialxfeaturelinear, 0-0-3', 'SIM, Direct, se2d_pointpooled, 0-0-3', 'SIM, Direct, se2d_fullgaussian2d, 0-0-3']:\n",
    "    data_ = pd.DataFrame((TrainedModel * Dataset * Model * Trainer * Seed * OracleScore * Experiments.Restrictions & 'experiment_name=\"{}\"'.format(experiment_name)).fetch())\n",
    "    data = pd.concat([data, data_])\n",
    "    \n",
    "data = pd.concat([data, data['dataset_config'].apply(pd.Series)], axis = 1).drop('dataset_config', axis = 1)\n",
    "data = pd.concat([data, data['model_config'].apply(pd.Series)], axis = 1).drop('model_config', axis = 1)\n",
    "data['Readout'] = [row.model_fn.split('.')[-1][5:] for loc, row in data.iterrows()]\n",
    "data = data.rename(columns = {'neuron_n': '# neurons', 'image_n': \"# images\"})\n",
    "direct_data = data.copy()\n",
    "direct_data['Condition'] = \"direct\"\n",
    "base_line = baseline(data=data, tier='test')\n",
    "\n",
    "# Filter out best performing models over model seeds\n",
    "direct_data = direct_data.sort_values('score', ascending=False).drop_duplicates(['Readout',\n",
    "                                                                   '# neurons',\n",
    "                                                                   '# images', \n",
    "                                                                   'neuron_base_seed',\n",
    "                                                                   'image_base_seed']).sort_values(['Readout', '# neurons', '# images'])\n",
    "\n",
    "\n",
    "# Full readout data\n",
    "data = pd.DataFrame()\n",
    "for experiment_name in [\"SIM, core_transfer (sameNI), se2d_fullgaussian2d, 0-0-3 -> 0-0-3, readout full I\",\n",
    "                        \"SIM, core_transfer (sameNI), se2d_pointpooled, 0-0-3 -> 0-0-3, readout full I\",\n",
    "                        \"SIM, core_transfer (sameNI), se2d_spatialxfeaturelinear, 0-0-3 -> 0-0-3, readout full I\"]:\n",
    "    data_ = pd.DataFrame((TrainedModelTransfer * Dataset * Model * Trainer * Seed * OracleScoreTransfer * Transfer.proj() * ExperimentsTransfer.Restrictions & 'experiment_name=\"{}\"'.format(experiment_name)).fetch())\n",
    "    transfer = get_transfer(old_experiment_name='SIM, Direct, {}, 0-0-3'.format(experiment_name.split(', ')[2]))\n",
    "    data_ = pd.merge(data_, transfer, how='inner', on=['transfer_hash', 'transfer_fn'])\n",
    "    data = pd.concat([data, data_])\n",
    "data['Readout'] = [row.model_fn.split('.')[-1][5:] for loc, row in data.iterrows()]\n",
    "data = data.rename(columns = {'t_neuron_n': '# neurons', 't_image_n': \"# images\"})\n",
    "full_readout_data = data.copy()\n",
    "full_readout_data['Condition'] = \"diff-core/best-readout\"\n",
    "\n",
    "# Full core data\n",
    "data = pd.DataFrame()\n",
    "for experiment_name in [\"SIM, core_transfer (best), se2d_fullgaussian2d, 0-0-3 -> 0-0-3\",\n",
    "                         \"SIM, core_transfer (best), se2d_pointpooled, 0-0-3 -> 0-0-3\",\n",
    "                         \"SIM, core_transfer (best), se2d_spatialxfeaturelinear, 0-0-3 -> 0-0-3\"]:\n",
    "    data_ = pd.DataFrame((TrainedModelTransfer * Dataset * Model * Trainer * Seed * OracleScoreTransfer * Transfer.proj() * ExperimentsTransfer.Restrictions & 'experiment_name=\"{}\"'.format(experiment_name)).fetch())\n",
    "    transfer = get_transfer(old_experiment_name='SIM, Direct, {}, 0-0-3'.format(experiment_name.split(', ')[2]))\n",
    "    data_ = pd.merge(data_, transfer, how='inner', on=['transfer_hash', 'transfer_fn'])\n",
    "    data = pd.concat([data, data_])\n",
    "data['Readout'] = [row.model_fn.split('.')[-1][5:] for loc, row in data.iterrows()]\n",
    "data = pd.concat([data, data['dataset_config'].apply(pd.Series)], axis = 1).drop('dataset_config', axis = 1)\n",
    "data = data.rename(columns = {'neuron_n': '# neurons', 'image_n': \"# images\"})\n",
    "full_core_data = data.copy()\n",
    "full_core_data['Condition'] = \"best-core/diff-readout\"\n",
    "\n",
    "data = pd.concat([direct_data, full_readout_data, full_core_data])\n",
    "data.replace({'Readout': {'spatialxfeaturelinear':'Factorized readout', 'fullgaussian2d':'Gaussian readout', 'pointpooled':'Point readout'}}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Simulated data triple plot'\n",
    "scoring_measure = \"fraction_oracle\" \n",
    "sns.set_context(\"paper\")        \n",
    "col_order = ['Factorized readout', 'Gaussian readout', 'Point readout']\n",
    "palette = [col for i, col in enumerate(sns.color_palette('bright')) if i in (5,6,8) ]\n",
    "\n",
    "paper_rc = {'lines.linewidth': 2, 'lines.markersize': 10}  \n",
    "with sns.plotting_context('paper', rc=paper_rc, font_scale=2.5), sns.color_palette('bright'), sns.axes_style('ticks'):        \n",
    "    g = sns.relplot(x=\"# images\", \n",
    "                    y=scoring_measure,\n",
    "                    hue=\"Condition\", \n",
    "                    col=\"Readout\",\n",
    "                    col_order=col_order,\n",
    "                    kind=\"line\",\n",
    "                    marker=\"o\",\n",
    "                    data=data,\n",
    "                   palette=palette,\n",
    "                   aspect=0.88)          \n",
    "    g.map(plt.axhline, y=base_line, c='k', ls='--', zorder=0, label= \"ground truth\")  \n",
    "       \n",
    "    g._legend.remove()\n",
    "    g.add_legend()\n",
    "    g.axes[0,0].set_ylabel(scoring_measure.replace('_', ' '))\n",
    "    g.axes[0,0].set_xlabel('# images')\n",
    "    g.axes[0,1].set_xlabel('# images')\n",
    "    g.axes[0,2].set_xlabel('# images')\n",
    "    g._legend.texts[0].set_text(\"\")\n",
    "    g._legend.set_bbox_to_anchor((.57,.46,.1,.1))\n",
    "    \n",
    "    for label in g._legend.texts:\n",
    "        label.set_size(25)\n",
    "    \n",
    "    for i, ax in enumerate(g.axes.flatten()): \n",
    "        ax.set_title(ax.get_title()[10:])\n",
    "        ax.text(-0.1, 1.09, string.ascii_uppercase[i], transform=ax.transAxes, \n",
    "        size=25, weight='bold')    \n",
    "        ax.yaxis.grid(True)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xticks(np.unique(data['# images']))\n",
    "        ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "        \n",
    "        ax.set_title(ax.get_title(), fontsize=30)\n",
    "        \n",
    "        if i > 0:\n",
    "            ax.set(xlabel=\"\")\n",
    "        else:\n",
    "            ax.set_xlabel(\"# images\", fontsize=30)\n",
    "            ax.set_ylabel(\"Fraction oracle\", fontsize=30)\n",
    "            \n",
    "    sns.despine(trim=True)\n",
    "    plt.tight_layout()\n",
    "#     g.fig.savefig('figures/' + title + '.pdf', dpi=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
